{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SpeechSplit_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliceInHunterland/colab/blob/main/SpeechSplit_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfb_IKpnk9cC",
        "outputId": "75ed21d0-8d94-4cd1-da67-ff262b2483d7"
      },
      "source": [
        "!git clone https://github.com/auspicious3000/SpeechSplit.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SpeechSplit'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 37 (delta 12), reused 34 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6kqtyOGlOpM",
        "outputId": "5d55aab8-5ee5-4850-8fe9-3de1701e6253"
      },
      "source": [
        "cd SpeechSplit/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq-aDHmql0KX",
        "outputId": "c547d043-ff86-41b0-dd08-da893dde5d75"
      },
      "source": [
        "cd assets/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrJkJYnunDV1",
        "outputId": "9ee73c6c-70f2-4896-dd61-cafb0db028c3"
      },
      "source": [
        "!gdown --id {\"1JF1WNS57wWcbmn1EztJxh09xU739j4_g\"} -O model.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JF1WNS57wWcbmn1EztJxh09xU739j4_g\n",
            "To: /content/SpeechSplit/assets/model.zip\n",
            "253MB [00:03, 75.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcfWB5CJnwkx",
        "outputId": "a7c3285e-c4ae-45b4-aa0a-64b673dde785"
      },
      "source": [
        "!gdown --id {\"1SZPPnWAgpGrh0gQ7bXQJXXjOntbh4hmz\"} -O autovc.ckpt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SZPPnWAgpGrh0gQ7bXQJXXjOntbh4hmz\n",
            "To: /content/SpeechSplit/assets/autovc.ckpt\n",
            "341MB [00:05, 64.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiR8MGvcnSv8",
        "outputId": "515b58b9-0533-4c39-da73-50d0e8afd586"
      },
      "source": [
        "!unzip model.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  model.zip\n",
            "  inflating: 640000-P.ckpt           \n",
            "  inflating: 660000-G.ckpt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m92MYkV8ll63",
        "outputId": "600e442d-70ce-4847-e49e-44f45f84c880"
      },
      "source": [
        "pip install wavenet_vocoder==0.1.1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wavenet_vocoder==0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/da/47da119dbd3cfc0c80b75270e4bc7b49b678bd94600928fa243922ad65bc/wavenet_vocoder-0.1.1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.4.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (0.8)\n",
            "Building wheels for collected packages: wavenet-vocoder\n",
            "  Building wheel for wavenet-vocoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavenet-vocoder: filename=wavenet_vocoder-0.1.1-cp36-none-any.whl size=12668 sha256=715be65bda79b937124fa83d11e7a290393a0af527c0557d58fc639f43e8bf06\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/fc/21/02d3785b65dd072b110b44b9df98b8cbf72a89ddea424ff0d9\n",
            "Successfully built wavenet-vocoder\n",
            "Installing collected packages: wavenet-vocoder\n",
            "Successfully installed wavenet-vocoder-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwN7iUrIq6_D",
        "outputId": "7383c1b8-9d18-4ec6-d5f2-02dd8b931656"
      },
      "source": [
        "!git clone https://github.com/auspicious3000/autovc.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'autovc'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 95 (delta 10), reused 60 (delta 3), pack-reused 23\u001b[K\n",
            "Unpacking objects: 100% (95/95), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORpxkFscpf1e",
        "outputId": "c946da02-ffa9-4284-9e7f-861fbcc47638"
      },
      "source": [
        "cd /content/SpeechSplit"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_86jxEobkZcG"
      },
      "source": [
        "# demo conversion\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from hparams import hparams\n",
        "from utils import pad_seq_to_2\n",
        "from utils import quantize_f0_numpy\n",
        "from model import Generator_3 as Generator\n",
        "from model import Generator_6 as F0_Converter\n",
        "\n",
        "\n",
        "device = 'cuda:0'\n",
        "G = Generator(hparams).eval().to(device)\n",
        "g_checkpoint = torch.load('assets/660000-G.ckpt', map_location=lambda storage, loc: storage)\n",
        "G.load_state_dict(g_checkpoint['model'])\n",
        "\n",
        "P = F0_Converter(hparams).eval().to(device)\n",
        "p_checkpoint = torch.load('assets/640000-P.ckpt', map_location=lambda storage, loc: storage)\n",
        "P.load_state_dict(p_checkpoint['model'])\n",
        "\n",
        "\n",
        "metadata = pickle.load(open('assets/demo.pkl', \"rb\"))\n",
        "\n",
        "\n",
        "sbmt_i = metadata[0]\n",
        "emb_org = torch.from_numpy(sbmt_i[1]).to(device)\n",
        "x_org, f0_org, len_org, uid_org = sbmt_i[2]        \n",
        "uttr_org_pad, len_org_pad = pad_seq_to_2(x_org[np.newaxis,:,:], 192)\n",
        "uttr_org_pad = torch.from_numpy(uttr_org_pad).to(device)\n",
        "f0_org_pad = np.pad(f0_org, (0, 192-len_org), 'constant', constant_values=(0, 0))\n",
        "f0_org_quantized = quantize_f0_numpy(f0_org_pad)[0]\n",
        "f0_org_onehot = f0_org_quantized[np.newaxis, :, :]\n",
        "f0_org_onehot = torch.from_numpy(f0_org_onehot).to(device)\n",
        "uttr_f0_org = torch.cat((uttr_org_pad, f0_org_onehot), dim=-1)\n",
        "\n",
        "sbmt_j = metadata[1]\n",
        "emb_trg = torch.from_numpy(sbmt_j[1]).to(device)\n",
        "x_trg, f0_trg, len_trg, uid_trg = sbmt_j[2]        \n",
        "uttr_trg_pad, len_trg_pad = pad_seq_to_2(x_trg[np.newaxis,:,:], 192)\n",
        "uttr_trg_pad = torch.from_numpy(uttr_trg_pad).to(device)\n",
        "f0_trg_pad = np.pad(f0_trg, (0, 192-len_trg), 'constant', constant_values=(0, 0))\n",
        "f0_trg_quantized = quantize_f0_numpy(f0_trg_pad)[0]\n",
        "f0_trg_onehot = f0_trg_quantized[np.newaxis, :, :]\n",
        "f0_trg_onehot = torch.from_numpy(f0_trg_onehot).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    f0_pred = P(uttr_org_pad, f0_trg_onehot)[0]\n",
        "    f0_pred_quantized = f0_pred.argmax(dim=-1).squeeze(0)\n",
        "    f0_con_onehot = torch.zeros((1, 192, 257), device=device)\n",
        "    f0_con_onehot[0, torch.arange(192), f0_pred_quantized] = 1\n",
        "uttr_f0_trg = torch.cat((uttr_org_pad, f0_con_onehot), dim=-1)    \n",
        "\n",
        "\n",
        "conditions = ['R', 'F', 'U', 'RF', 'RU', 'FU', 'RFU']\n",
        "spect_vc = []\n",
        "with torch.no_grad():\n",
        "    for condition in conditions:\n",
        "        if condition == 'R':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_trg_pad, emb_org)\n",
        "        if condition == 'F':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_org_pad, emb_org)\n",
        "        if condition == 'U':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_org_pad, emb_trg)\n",
        "        if condition == 'RF':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_trg_pad, emb_org)\n",
        "        if condition == 'RU':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_trg_pad, emb_trg)\n",
        "        if condition == 'FU':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_org_pad, emb_trg)\n",
        "        if condition == 'RFU':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_trg_pad, emb_trg)\n",
        "            \n",
        "        if 'R' in condition:\n",
        "            uttr_trg = x_identic_val[0, :len_trg, :].cpu().numpy()\n",
        "        else:\n",
        "            uttr_trg = x_identic_val[0, :len_org, :].cpu().numpy()\n",
        "                \n",
        "        spect_vc.append( ('{}_{}_{}_{}'.format(sbmt_i[0], sbmt_j[0], uid_org, condition), uttr_trg ) )       "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kab6zhq22iSx"
      },
      "source": [
        "!touch /content/SpeechSplit/assets/autovc/__init__.py\r\n",
        "!touch /content/SpeechSplit/assets/__init__.py\r\n",
        "!touch /content/SpeechSplit/__init__.py\r\n",
        "!cd /content/SpeechSplit/assets/autovc\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG1KQZdSZtvj",
        "outputId": "3b166a19-98ba-4932-fcd1-1522b4848569"
      },
      "source": [
        "cd /content/SpeechSplit/assets/autovc"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit/assets/autovc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzz2urcCZvtG"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLpQ9w6zZn66"
      },
      "source": [
        "!mv hparams.py hparam.py"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-36KxVns3eFd",
        "outputId": "de01e5c0-15a4-4ba2-f6a9-041d823ee5a3"
      },
      "source": [
        "cd /content/SpeechSplit"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "173eO0-EH24Q",
        "outputId": "b91aa5b6-06bc-45ff-b955-11f387497863"
      },
      "source": [
        "ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/         hparams.py   main.py           model.py      solver.py\n",
            "data_loader.py  __init__.py  make_metadata.py  \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34mtfcompat\u001b[0m/\n",
            "demo.ipynb      LICENSE      make_spect_f0.py  README.md     utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y20SYhyDLZdj"
      },
      "source": [
        " \r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        " in synthesis.py change imports to \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "from assets.autovc.hparam import hparams\r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7CuFKnRZKc5"
      },
      "source": [
        "!pip install numba==0.48\r\n",
        "!pip install librosa==0.6.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwmDEH_HsJTQ",
        "outputId": "57108e2b-9f3c-4b6f-ff4b-ced39c275190"
      },
      "source": [
        "import torch\r\n",
        "import librosa\r\n",
        "import pickle\r\n",
        "import os\r\n",
        "import soundfile as sf\r\n",
        "print(librosa.__version__)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azkg-IowkZcO",
        "outputId": "11bf84ff-0a47-4c61-c565-be89e53c75b1"
      },
      "source": [
        "\n",
        "# spectrogram to waveform\n",
        "import torch\n",
        "import librosa\n",
        "import pickle\n",
        "import os\n",
        "import soundfile as sf\n",
        "from assets.autovc.synthesis import build_model, wavegen\n",
        "#from  os\n",
        "#from speechsplit.assets.autovc. import synthesis\n",
        "#from assets.autovc import *\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n",
        "\n",
        "model = build_model().to(device)\n",
        "#checkpoint = torch.load(\"/content/SpeechSplit/assets/checkpoint_step001000000_ema.pth\")\n",
        "#model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "for spect in spect_vc:\n",
        "    name = spect[0]\n",
        "    c = spect[1]\n",
        "    print(name)\n",
        "    waveform = wavegen(model, c=c)   \n",
        "    librosa.output.write_wav('results/'+name+'.wav', waveform, sr=16000)\n",
        "    #sf.write('results/'+name+'.wav', waveform,16000 ,'PCM_24')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 3/26880 [00:00<15:27, 28.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "p226_p231_003002_R\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26880/26880 [06:28<00:00, 69.26it/s]\n",
            "  0%|          | 8/34560 [00:00<08:04, 71.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "p226_p231_003002_F\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34560/34560 [08:17<00:00, 69.42it/s]\n",
            "  0%|          | 7/34560 [00:00<08:52, 64.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "p226_p231_003002_U\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 23620/34560 [05:39<03:08, 57.96it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PevmpBveK_7W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}