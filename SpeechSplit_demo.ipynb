{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SpeechSplit_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliceInHunterland/colab/blob/main/SpeechSplit_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7CuFKnRZKc5",
        "outputId": "4b52d2f1-bb04-4484-b517-39fa84ba5ab5"
      },
      "source": [
        "!pip install numba==0.48\r\n",
        "!pip install librosa==0.6.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numba==0.48\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/7f/dbe85f5f419dca88509d829df90dfa5aefa39c39f6b7020dfc206a386279/numba-0.48.0-1-cp36-cp36m-manylinux2014_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 13.8MB/s \n",
            "\u001b[?25hCollecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/bb/60d4033d56c9da36490af19caa6c794b72b8aef6f792fdfa8cb95d11e419/llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.48) (53.0.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba==0.48) (1.19.5)\n",
            "\u001b[31mERROR: umap-learn 0.5.0 has requirement numba>=0.49, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pynndescent 0.5.1 has requirement numba>=0.51.2, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: llvmlite, numba\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.31.0 numba-0.48.0\n",
            "Collecting librosa==0.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/7e/7a0f66f79a70a0a4c163ecf30429f6c1644c88654f135a9eee0bda457626/librosa-0.6.3.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (1.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (4.4.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (1.15.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.3) (0.48.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa==0.6.3) (53.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa==0.6.3) (0.31.0)\n",
            "Building wheels for collected packages: librosa\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.6.3-cp36-none-any.whl size=1573317 sha256=46bb89f92d7bf584fa9831a26ca77d0a27a890a8c4c6c6321234347b3d4ce2b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/49/68/87ba660f30e3977f0778e39ee2e944629cd37c2a0ce41f9ff1\n",
            "Successfully built librosa\n",
            "Installing collected packages: librosa\n",
            "  Found existing installation: librosa 0.8.0\n",
            "    Uninstalling librosa-0.8.0:\n",
            "      Successfully uninstalled librosa-0.8.0\n",
            "Successfully installed librosa-0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH2ve8-2mMQ9",
        "outputId": "eb5c2f50-92f6-4c64-d4a2-76660fd35570"
      },
      "source": [
        "import librosa\r\n",
        "print(librosa.__version__) #should be 0.6.3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfb_IKpnk9cC",
        "outputId": "6ea1bdac-e5b4-4dda-f636-ebf76186b97e"
      },
      "source": [
        "!git clone https://github.com/auspicious3000/SpeechSplit.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SpeechSplit'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 37 (delta 12), reused 34 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6kqtyOGlOpM",
        "outputId": "9376714f-48e1-4c20-833c-ba38191b92a3"
      },
      "source": [
        "cd SpeechSplit/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq-aDHmql0KX",
        "outputId": "c29c6ff6-3ae4-4b67-8f16-62e414ffe472"
      },
      "source": [
        "cd assets/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrJkJYnunDV1",
        "outputId": "4d9b93af-34fd-47c7-fadc-47630588cb8d"
      },
      "source": [
        "!gdown --id {\"1JF1WNS57wWcbmn1EztJxh09xU739j4_g\"} -O model.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JF1WNS57wWcbmn1EztJxh09xU739j4_g\n",
            "To: /content/SpeechSplit/assets/model.zip\n",
            "253MB [00:02, 85.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a16xrbH4i_JA",
        "outputId": "46e6f294-7417-48d3-ef24-2545f864aa5e"
      },
      "source": [
        "!gdown --id 1Zksy0ndlDezo9wclQNZYkGi_6i7zi4nQ -O checkpoint_step001000000_ema.pth"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Zksy0ndlDezo9wclQNZYkGi_6i7zi4nQ\n",
            "To: /content/SpeechSplit/assets/checkpoint_step001000000_ema.pth\n",
            "297MB [00:04, 60.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcfWB5CJnwkx",
        "outputId": "dac09a66-95a0-4dc4-ac5a-dce3127bb832"
      },
      "source": [
        "!gdown --id {\"1SZPPnWAgpGrh0gQ7bXQJXXjOntbh4hmz\"} -O autovc.ckpt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SZPPnWAgpGrh0gQ7bXQJXXjOntbh4hmz\n",
            "To: /content/SpeechSplit/assets/autovc.ckpt\n",
            "341MB [00:04, 68.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiR8MGvcnSv8",
        "outputId": "d642fe7c-66d8-4826-a5a8-d35d53b18292"
      },
      "source": [
        "!unzip model.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  model.zip\n",
            "  inflating: 640000-P.ckpt           \n",
            "  inflating: 660000-G.ckpt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m92MYkV8ll63",
        "outputId": "e29df410-9d9d-457c-815c-078dc05eb0ec"
      },
      "source": [
        "pip install wavenet_vocoder==0.1.1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wavenet_vocoder==0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/da/47da119dbd3cfc0c80b75270e4bc7b49b678bd94600928fa243922ad65bc/wavenet_vocoder-0.1.1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.4.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (0.8)\n",
            "Building wheels for collected packages: wavenet-vocoder\n",
            "  Building wheel for wavenet-vocoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavenet-vocoder: filename=wavenet_vocoder-0.1.1-cp36-none-any.whl size=12668 sha256=716c67bf9f29a31fcf82a21125a02b6d5fa8e311c510101f66e706e7f7eacbab\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/fc/21/02d3785b65dd072b110b44b9df98b8cbf72a89ddea424ff0d9\n",
            "Successfully built wavenet-vocoder\n",
            "Installing collected packages: wavenet-vocoder\n",
            "Successfully installed wavenet-vocoder-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwN7iUrIq6_D",
        "outputId": "16e67e22-02a6-4b38-a5de-fd70a319996a"
      },
      "source": [
        "!git clone https://github.com/auspicious3000/autovc.git"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'autovc'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 95 (delta 10), reused 60 (delta 3), pack-reused 23\u001b[K\n",
            "Unpacking objects: 100% (95/95), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORpxkFscpf1e",
        "outputId": "ff354ef2-94ba-499b-b37f-aa3ab2fd5943"
      },
      "source": [
        "cd /content/SpeechSplit"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_86jxEobkZcG"
      },
      "source": [
        "# demo conversion\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from hparams import hparams\n",
        "from utils import pad_seq_to_2\n",
        "from utils import quantize_f0_numpy\n",
        "from model import Generator_3 as Generator\n",
        "from model import Generator_6 as F0_Converter\n",
        "\n",
        "\n",
        "device = 'cuda:0'\n",
        "G = Generator(hparams).eval().to(device)\n",
        "g_checkpoint = torch.load('assets/660000-G.ckpt', map_location=lambda storage, loc: storage)\n",
        "G.load_state_dict(g_checkpoint['model'])\n",
        "\n",
        "P = F0_Converter(hparams).eval().to(device)\n",
        "p_checkpoint = torch.load('assets/640000-P.ckpt', map_location=lambda storage, loc: storage)\n",
        "P.load_state_dict(p_checkpoint['model'])\n",
        "\n",
        "\n",
        "metadata = pickle.load(open('assets/demo.pkl', \"rb\"))\n",
        "\n",
        "\n",
        "sbmt_i = metadata[0]\n",
        "emb_org = torch.from_numpy(sbmt_i[1]).to(device)\n",
        "x_org, f0_org, len_org, uid_org = sbmt_i[2]        \n",
        "uttr_org_pad, len_org_pad = pad_seq_to_2(x_org[np.newaxis,:,:], 192)\n",
        "uttr_org_pad = torch.from_numpy(uttr_org_pad).to(device)\n",
        "f0_org_pad = np.pad(f0_org, (0, 192-len_org), 'constant', constant_values=(0, 0))\n",
        "f0_org_quantized = quantize_f0_numpy(f0_org_pad)[0]\n",
        "f0_org_onehot = f0_org_quantized[np.newaxis, :, :]\n",
        "f0_org_onehot = torch.from_numpy(f0_org_onehot).to(device)\n",
        "uttr_f0_org = torch.cat((uttr_org_pad, f0_org_onehot), dim=-1)\n",
        "\n",
        "sbmt_j = metadata[1]\n",
        "emb_trg = torch.from_numpy(sbmt_j[1]).to(device)\n",
        "x_trg, f0_trg, len_trg, uid_trg = sbmt_j[2]        \n",
        "uttr_trg_pad, len_trg_pad = pad_seq_to_2(x_trg[np.newaxis,:,:], 192)\n",
        "uttr_trg_pad = torch.from_numpy(uttr_trg_pad).to(device)\n",
        "f0_trg_pad = np.pad(f0_trg, (0, 192-len_trg), 'constant', constant_values=(0, 0))\n",
        "f0_trg_quantized = quantize_f0_numpy(f0_trg_pad)[0]\n",
        "f0_trg_onehot = f0_trg_quantized[np.newaxis, :, :]\n",
        "f0_trg_onehot = torch.from_numpy(f0_trg_onehot).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    f0_pred = P(uttr_org_pad, f0_trg_onehot)[0]\n",
        "    f0_pred_quantized = f0_pred.argmax(dim=-1).squeeze(0)\n",
        "    f0_con_onehot = torch.zeros((1, 192, 257), device=device)\n",
        "    f0_con_onehot[0, torch.arange(192), f0_pred_quantized] = 1\n",
        "uttr_f0_trg = torch.cat((uttr_org_pad, f0_con_onehot), dim=-1)    \n",
        "\n",
        "\n",
        "conditions = ['R', 'F', 'U', 'RF', 'RU', 'FU', 'RFU']\n",
        "spect_vc = []\n",
        "with torch.no_grad():\n",
        "    for condition in conditions:\n",
        "        if condition == 'R':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_trg_pad, emb_org)\n",
        "        if condition == 'F':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_org_pad, emb_org)\n",
        "        if condition == 'U':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_org_pad, emb_trg)\n",
        "        if condition == 'RF':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_trg_pad, emb_org)\n",
        "        if condition == 'RU':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_trg_pad, emb_trg)\n",
        "        if condition == 'FU':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_org_pad, emb_trg)\n",
        "        if condition == 'RFU':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_trg_pad, emb_trg)\n",
        "            \n",
        "        if 'R' in condition:\n",
        "            uttr_trg = x_identic_val[0, :len_trg, :].cpu().numpy()\n",
        "        else:\n",
        "            uttr_trg = x_identic_val[0, :len_org, :].cpu().numpy()\n",
        "                \n",
        "        spect_vc.append( ('{}_{}_{}_{}'.format(sbmt_i[0], sbmt_j[0], uid_org, condition), uttr_trg ) )       "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kab6zhq22iSx"
      },
      "source": [
        "!touch /content/SpeechSplit/assets/autovc/__init__.py\r\n",
        "!touch /content/SpeechSplit/assets/__init__.py\r\n",
        "!touch /content/SpeechSplit/__init__.py\r\n",
        "!cd /content/SpeechSplit/assets/autovc\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG1KQZdSZtvj",
        "outputId": "8144f01b-bf59-4e7e-edcb-3278a800fd72"
      },
      "source": [
        "cd /content/SpeechSplit/assets/autovc"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit/assets/autovc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzz2urcCZvtG",
        "outputId": "fe3b36c9-e4dc-46bf-9c23-704c11da0a2b"
      },
      "source": [
        "ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conversion.ipynb  LICENSE           metadata.pkl  results.pkl        \u001b[0m\u001b[01;34mwavs\u001b[0m/\n",
            "data_loader.py    main.py           model_bl.py   solver_encoder.py\n",
            "hparams.py        make_metadata.py  model_vc.py   synthesis.py\n",
            "__init__.py       make_spect.py     README.md     vocoder.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLpQ9w6zZn66"
      },
      "source": [
        "!mv hparams.py hparam.py"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-36KxVns3eFd",
        "outputId": "791beedb-2a2e-4915-cebd-8e66cda03d37"
      },
      "source": [
        "cd /content/SpeechSplit"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "173eO0-EH24Q",
        "outputId": "ecf38b3f-0a39-4095-f735-d514d82eb605"
      },
      "source": [
        "ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/         hparams.py   main.py           model.py      solver.py\n",
            "data_loader.py  __init__.py  make_metadata.py  \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34mtfcompat\u001b[0m/\n",
            "demo.ipynb      LICENSE      make_spect_f0.py  README.md     utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbVQ48l2e4pX"
      },
      "source": [
        "# coding: utf-8\r\n",
        "\"\"\"\r\n",
        "Synthesis waveform from trained WaveNet.\r\n",
        "\r\n",
        "Modified from https://github.com/r9y9/wavenet_vocoder\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "import librosa\r\n",
        "from assets.autovc.hparam import hparams\r\n",
        "from wavenet_vocoder import builder\r\n",
        "\r\n",
        "torch.set_num_threads(4)\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
        "\r\n",
        "\r\n",
        "def build_model():\r\n",
        "    \r\n",
        "    model = getattr(builder, hparams.builder)(\r\n",
        "        out_channels=hparams.out_channels,\r\n",
        "        layers=hparams.layers,\r\n",
        "        stacks=hparams.stacks,\r\n",
        "        residual_channels=hparams.residual_channels,\r\n",
        "        gate_channels=hparams.gate_channels,\r\n",
        "        skip_out_channels=hparams.skip_out_channels,\r\n",
        "        cin_channels=hparams.cin_channels,\r\n",
        "        gin_channels=hparams.gin_channels,\r\n",
        "        weight_normalization=hparams.weight_normalization,\r\n",
        "        n_speakers=hparams.n_speakers,\r\n",
        "        dropout=hparams.dropout,\r\n",
        "        kernel_size=hparams.kernel_size,\r\n",
        "        upsample_conditional_features=hparams.upsample_conditional_features,\r\n",
        "        upsample_scales=hparams.upsample_scales,\r\n",
        "        freq_axis_kernel_size=hparams.freq_axis_kernel_size,\r\n",
        "        scalar_input=True,\r\n",
        "        legacy=hparams.legacy,\r\n",
        "    )\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def wavegen(model, c=None, tqdm=tqdm):\r\n",
        "    \"\"\"Generate waveform samples by WaveNet.\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    model.make_generation_fast_()\r\n",
        "\r\n",
        "    Tc = c.shape[0]\r\n",
        "    upsample_factor = hparams.hop_size\r\n",
        "    # Overwrite length according to feature size\r\n",
        "    length = Tc * upsample_factor\r\n",
        "\r\n",
        "    # B x C x T\r\n",
        "    c = torch.FloatTensor(c.T).unsqueeze(0)\r\n",
        "\r\n",
        "    initial_input = torch.zeros(1, 1, 1).fill_(0.0)\r\n",
        "\r\n",
        "    # Transform data to GPU\r\n",
        "    initial_input = initial_input.to(device)\r\n",
        "    c = None if c is None else c.to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        y_hat = model.incremental_forward(\r\n",
        "            initial_input, c=c, g=None, T=length, tqdm=tqdm, softmax=True, quantize=True,\r\n",
        "            log_scale_min=hparams.log_scale_min)\r\n",
        "\r\n",
        "    y_hat = y_hat.view(-1).cpu().data.numpy()\r\n",
        "\r\n",
        "    return y_hat"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azkg-IowkZcO",
        "outputId": "99ab066f-9303-42b3-b6eb-a850e506809b"
      },
      "source": [
        "\n",
        "# spectrogram to waveform\n",
        "import torch\n",
        "import librosa\n",
        "import pickle\n",
        "import os\n",
        "import soundfile as sf\n",
        "#from assets.autovc.synthesis import build_model, wavegen\n",
        "#from  os\n",
        "#from speechsplit.assets.autovc. import synthesis\n",
        "#from assets.autovc import *\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n",
        "\n",
        "model = build_model().to(device)\n",
        "checkpoint = torch.load(\"/content/SpeechSplit/assets/checkpoint_step001000000_ema.pth\")\n",
        "model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "for spect in spect_vc:\n",
        "    name = spect[0]\n",
        "    c = spect[1]\n",
        "    print(name)\n",
        "    waveform = wavegen(model, c=c)   \n",
        "    librosa.output.write_wav('results/'+name+'.wav', waveform, sr=16000)\n",
        "    #sf.write('results/'+name+'.wav', waveform,16000 ,'PCM_24')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 5/26880 [00:00<09:48, 45.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "p226_p231_003002_R\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26880/26880 [05:38<00:00, 79.34it/s]\n",
            "  0%|          | 9/34560 [00:00<06:38, 86.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "p226_p231_003002_F\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 22711/34560 [04:40<02:29, 79.17it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PevmpBveK_7W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}