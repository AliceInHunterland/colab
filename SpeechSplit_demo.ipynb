{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Копия блокнота \"demo.ipynb\"",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliceInHunterland/colab/blob/main/SpeechSplit_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmgSq8O8kvAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39284664-02a1-4cb8-acc0-cf7c63100c37"
      },
      "source": [
        "pip install hparams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hparams\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ec/bcc7011ec23390ac0ccafd031ad9f850430390b4ed3a8b1550788b7fe586/hparams-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from hparams) (2.7.1)\n",
            "Installing collected packages: hparams\n",
            "Successfully installed hparams-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfb_IKpnk9cC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d180d8-733d-4def-ca8b-5ad9847a079c"
      },
      "source": [
        "!git clone https://github.com/auspicious3000/SpeechSplit.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SpeechSplit'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 37 (delta 12), reused 34 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6kqtyOGlOpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb65af2-34f0-4e29-eb84-47924cdadae7"
      },
      "source": [
        "cd SpeechSplit/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq-aDHmql0KX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0711a59-713c-422a-b531-a8646352f142"
      },
      "source": [
        "cd assets/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SpeechSplit/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrJkJYnunDV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb91498-8125-4998-88f8-9de541310483"
      },
      "source": [
        "!gdown --id {\"1JF1WNS57wWcbmn1EztJxh09xU739j4_g\"} -O model.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JF1WNS57wWcbmn1EztJxh09xU739j4_g\n",
            "To: /content/SpeechSplit/assets/model.zip\n",
            "253MB [00:03, 73.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcfWB5CJnwkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b16024-116a-4c59-909c-ceb22cf8fcbe"
      },
      "source": [
        "!gdown --id {\"1SZPPnWAgpGrh0gQ7bXQJXXjOntbh4hmz\"} -O autovc.ckpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SZPPnWAgpGrh0gQ7bXQJXXjOntbh4hmz\n",
            "To: /content/SpeechSplit/assets/autovc.ckpt\n",
            "341MB [00:05, 62.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiR8MGvcnSv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1fd18c-803e-4b1b-96c7-456596144483"
      },
      "source": [
        "!unzip model.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  model.zip\n",
            "  inflating: 640000-P.ckpt           \n",
            "  inflating: 660000-G.ckpt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m92MYkV8ll63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9710a4d-a902-48d8-a8a7-0f50d3bdfece"
      },
      "source": [
        "pip install wavenet_vocoder==0.1.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wavenet_vocoder==0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/da/47da119dbd3cfc0c80b75270e4bc7b49b678bd94600928fa243922ad65bc/wavenet_vocoder-0.1.1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.4.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from wavenet_vocoder==0.1.1) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->wavenet_vocoder==0.1.1) (3.7.4.3)\n",
            "Building wheels for collected packages: wavenet-vocoder\n",
            "  Building wheel for wavenet-vocoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavenet-vocoder: filename=wavenet_vocoder-0.1.1-cp36-none-any.whl size=12668 sha256=bc124e7a8f282cf452689fe4a65042a8a3e2a0a7394b493a8cd4fc20ac6f6618\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/fc/21/02d3785b65dd072b110b44b9df98b8cbf72a89ddea424ff0d9\n",
            "Successfully built wavenet-vocoder\n",
            "Installing collected packages: wavenet-vocoder\n",
            "Successfully installed wavenet-vocoder-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_86jxEobkZcG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4a1c14c9-bb8d-4b96-ae83-e6393ccf777a"
      },
      "source": [
        "# demo conversion\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from hparams import hparams\n",
        "from utils import pad_seq_to_2\n",
        "from utils import quantize_f0_numpy\n",
        "from model import Generator_3 as Generator\n",
        "from model import Generator_6 as F0_Converter\n",
        "\n",
        "\n",
        "device = 'cuda:0'\n",
        "G = Generator(hparams).eval().to(device)\n",
        "g_checkpoint = torch.load('assets/660000-G.ckpt', map_location=lambda storage, loc: storage)\n",
        "G.load_state_dict(g_checkpoint['model'])\n",
        "\n",
        "P = F0_Converter(hparams).eval().to(device)\n",
        "p_checkpoint = torch.load('assets/640000-P.ckpt', map_location=lambda storage, loc: storage)\n",
        "P.load_state_dict(p_checkpoint['model'])\n",
        "\n",
        "\n",
        "metadata = pickle.load(open('assets/demo.pkl', \"rb\"))\n",
        "\n",
        "\n",
        "sbmt_i = metadata[0]\n",
        "emb_org = torch.from_numpy(sbmt_i[1]).to(device)\n",
        "x_org, f0_org, len_org, uid_org = sbmt_i[2]        \n",
        "uttr_org_pad, len_org_pad = pad_seq_to_2(x_org[np.newaxis,:,:], 192)\n",
        "uttr_org_pad = torch.from_numpy(uttr_org_pad).to(device)\n",
        "f0_org_pad = np.pad(f0_org, (0, 192-len_org), 'constant', constant_values=(0, 0))\n",
        "f0_org_quantized = quantize_f0_numpy(f0_org_pad)[0]\n",
        "f0_org_onehot = f0_org_quantized[np.newaxis, :, :]\n",
        "f0_org_onehot = torch.from_numpy(f0_org_onehot).to(device)\n",
        "uttr_f0_org = torch.cat((uttr_org_pad, f0_org_onehot), dim=-1)\n",
        "\n",
        "sbmt_j = metadata[1]\n",
        "emb_trg = torch.from_numpy(sbmt_j[1]).to(device)\n",
        "x_trg, f0_trg, len_trg, uid_trg = sbmt_j[2]        \n",
        "uttr_trg_pad, len_trg_pad = pad_seq_to_2(x_trg[np.newaxis,:,:], 192)\n",
        "uttr_trg_pad = torch.from_numpy(uttr_trg_pad).to(device)\n",
        "f0_trg_pad = np.pad(f0_trg, (0, 192-len_trg), 'constant', constant_values=(0, 0))\n",
        "f0_trg_quantized = quantize_f0_numpy(f0_trg_pad)[0]\n",
        "f0_trg_onehot = f0_trg_quantized[np.newaxis, :, :]\n",
        "f0_trg_onehot = torch.from_numpy(f0_trg_onehot).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    f0_pred = P(uttr_org_pad, f0_trg_onehot)[0]\n",
        "    f0_pred_quantized = f0_pred.argmax(dim=-1).squeeze(0)\n",
        "    f0_con_onehot = torch.zeros((1, 192, 257), device=device)\n",
        "    f0_con_onehot[0, torch.arange(192), f0_pred_quantized] = 1\n",
        "uttr_f0_trg = torch.cat((uttr_org_pad, f0_con_onehot), dim=-1)    \n",
        "\n",
        "\n",
        "conditions = ['R', 'F', 'U', 'RF', 'RU', 'FU', 'RFU']\n",
        "spect_vc = []\n",
        "with torch.no_grad():\n",
        "    for condition in conditions:\n",
        "        if condition == 'R':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_trg_pad, emb_org)\n",
        "        if condition == 'F':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_org_pad, emb_org)\n",
        "        if condition == 'U':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_org_pad, emb_trg)\n",
        "        if condition == 'RF':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_trg_pad, emb_org)\n",
        "        if condition == 'RU':\n",
        "            x_identic_val = G(uttr_f0_org, uttr_trg_pad, emb_trg)\n",
        "        if condition == 'FU':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_org_pad, emb_trg)\n",
        "        if condition == 'RFU':\n",
        "            x_identic_val = G(uttr_f0_trg, uttr_trg_pad, emb_trg)\n",
        "            \n",
        "        if 'R' in condition:\n",
        "            uttr_trg = x_identic_val[0, :len_trg, :].cpu().numpy()\n",
        "        else:\n",
        "            uttr_trg = x_identic_val[0, :len_org, :].cpu().numpy()\n",
        "                \n",
        "        spect_vc.append( ('{}_{}_{}_{}'.format(sbmt_i[0], sbmt_j[0], uid_org, condition), uttr_trg ) )       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3e6537d2a557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mg_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'assets/660000-G.ckpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_checkpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SpeechSplit/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparams)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder_7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SpeechSplit/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparams)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_neck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_neck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq_3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'hparams.hparams' has no attribute 'dim_neck'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azkg-IowkZcO"
      },
      "source": [
        "# spectrogram to waveform\n",
        "import torch\n",
        "import librosa\n",
        "import pickle\n",
        "import os\n",
        "from synthesis import build_model\n",
        "from synthesis import wavegen\n",
        "\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n",
        "\n",
        "model = build_model().to(device)\n",
        "checkpoint = torch.load(\"assets/checkpoint_step001000000_ema.pth\")\n",
        "model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "for spect in spect_vc:\n",
        "    name = spect[0]\n",
        "    c = spect[1]\n",
        "    print(name)\n",
        "    waveform = wavegen(model, c=c)   \n",
        "    librosa.output.write_wav('results/'+name+'.wav', waveform, sr=16000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}